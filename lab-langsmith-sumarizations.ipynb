{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52bb9c6d-7a1c-480a-93c9-acf847773163",
      "metadata": {
        "id": "52bb9c6d-7a1c-480a-93c9-acf847773163"
      },
      "source": [
        "# Lab | Summarization evaluation using LangSmith\n",
        "Let's revisit your capstone project 2? Well, sort of. Pick diffierent sets of data and re-run this notebook. Maybe parts of the dataset you used in your last project week. The point is for you to understand all steps involve and the many different ways one can and should evaluate LLM applications using LangSmith.\n",
        "\n",
        "What did you learn? - Let's discuss that in class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets numpy langchain langchain_openai langchain-pinecone pinecone-notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MeTltJRpCbu",
        "outputId": "19c1b6bb-4d50-4137-81a2-350d9914db47"
      },
      "id": "8MeTltJRpCbu",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain-pinecone in /usr/local/lib/python3.11/dist-packages (0.2.5)\n",
            "Requirement already satisfied: pinecone-notebooks in /usr/local/lib/python3.11/dist-packages (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.10.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.55)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: pinecone<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (6.0.2)\n",
            "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain-pinecone) (0.3.19)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (8.3.5)\n",
            "Requirement already satisfied: pytest-asyncio<1,>=0.20 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.26.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
            "Requirement already satisfied: syrupy<5,>=4 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.1)\n",
            "Requirement already satisfied: pytest-socket<1,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.7.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (2.3.0)\n",
            "\u001b[33mWARNING: pinecone 6.0.2 does not provide the extra 'async'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone<7.0.0,>=6.0.0->pinecone[async]<7.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9",
      "metadata": {
        "id": "00830bb4-eb0f-4439-9ceb-c5956d28a8a9"
      },
      "source": [
        "## LangSmith - LangChain evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
      "metadata": {
        "id": "6db4887a-a214-49bc-9bb6-0ae59c1092ec",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "#_ = load_dotenv(find_dotenv())\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "OPENAI_API_KEY  = userdata.get('OPENAI_API_KEY')\n",
        "LANGCHAIN_API_KEY = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "HUGGINGFACEHUB_API_TOKEN = userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
      "metadata": {
        "id": "5f4adff9-1169-4173-a72b-c983dcb6160d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"langsmith_max-test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
      "metadata": {
        "id": "0189af0e-8145-407b-a32d-2f21ac0ca5ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Importing Client from Langsmith\n",
        "from langsmith import Client\n",
        "client = Client(api_key=LANGCHAIN_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2",
      "metadata": {
        "id": "4e7c4be2-fdae-42cf-b1b2-9aef89081ad2"
      },
      "source": [
        "### Create Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install numpy==1.23.5 --upgrade --force-reinstall"
      ],
      "metadata": {
        "id": "HA63tzZmprMX"
      },
      "id": "HA63tzZmprMX",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
      "metadata": {
        "id": "dbc219ae-1760-4f3d-92e6-aaeb6fb7ee9f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "cnn_dataset = load_dataset(\n",
        "    \"ccdv/cnn_dailymail\", version\n",
        "    =\"3.0.0\",\n",
        "    trust_remote_code=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
      "metadata": {
        "id": "7684f9ef-f665-42c1-ac89-f2726f7ae0da",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def add_prefix(example):\n",
        "    return {\n",
        "        **example,\n",
        "        \"article\": f\"Summarize this news:\\n{example['article']}\"\n",
        "    }\n",
        "\n",
        "#cnn_dataset = cnn_dataset.map(add_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b54b146-e870-4721-a0ae-03401d52d8ac",
        "outputId": "8243bcb9-2fd3-4da3-eb55-7f843b714a44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "cnn_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4925ad37-55f3-44b1-9c46-3adcc8c58942",
        "outputId": "2a728b4a-63e3-4cc0-eaf8-d227f1f08a74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': 'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .',\n",
              " 'highlights': 'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .',\n",
              " 'id': '0001d1afc246a7964130f43ae940af6bc6c57f01'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "cnn_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fc26871-68d9-4ab1-a9c9-b6caf241d636",
        "outputId": "a4d7e90c-104c-4ed1-c1fe-3fad60f82444",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['article', 'highlights', 'id'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#Get just a few news to test\n",
        "MAX_NEWS=10\n",
        "sample_cnn = cnn_dataset[\"test\"].select(range(MAX_NEWS)).map(add_prefix)\n",
        "\n",
        "sample_cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc0ef576-ea25-446d-a99b-354678a274ba",
      "metadata": {
        "id": "bc0ef576-ea25-446d-a99b-354678a274ba"
      },
      "source": [
        "The dataset contains three columns: article, highlights, and id. To use LangSmith, we need to create a dataset in LangSmith format.\n",
        "\n",
        "LangSmith expects a prompt and a result. To achieve this, we will transform the article into a prompt by adding the prefix: \"Summarize this news.\" As a result, we will use the content of highlights, which represents the summaries created by humans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e3cea3a-fde5-4e52-90f9-d1db4fd30bc2",
        "outputId": "eda8edba-9ade-4509-cd0d-30e369b857a3",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'article': 'Summarize this news:\\n(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. He was 88. Best died in hospice in Hickory, North Carolina, of complications from pneumonia, said Steve Latshaw, a longtime friend and Hollywood colleague. Although he\\'d been a busy actor for decades in theater and in Hollywood, Best didn\\'t become famous until 1979, when \"The Dukes of Hazzard\\'s\" cornpone charms began beaming into millions of American homes almost every Friday night. For seven seasons, Best\\'s Rosco P. Coltrane chased the moonshine-running Duke boys back and forth across the back roads of fictitious Hazzard County, Georgia, although his \"hot pursuit\" usually ended with him crashing his patrol car. Although Rosco was slow-witted and corrupt, Best gave him a childlike enthusiasm that got laughs and made him endearing. His character became known for his distinctive \"kew-kew-kew\" chuckle and for goofy catchphrases such as \"cuff \\'em and stuff \\'em!\" upon making an arrest. Among the most popular shows on TV in the early \\'80s, \"The Dukes of Hazzard\" ran until 1985 and spawned TV movies, an animated series and video games. Several of Best\\'s \"Hazzard\" co-stars paid tribute to the late actor on social media. \"I laughed and learned more from Jimmie in one hour than from anyone else in a whole year,\" co-star John Schneider, who played Bo Duke, said on Twitter. \"Give Uncle Jesse my love when you see him dear friend.\" \"Jimmy Best was the most constantly creative person I have ever known,\" said Ben Jones, who played mechanic Cooter on the show, in a Facebook post. \"Every minute of his long life was spent acting, writing, producing, painting, teaching, fishing, or involved in another of his life\\'s many passions.\" Born Jewel Guy on July 26, 1926, in Powderly, Kentucky, Best was orphaned at 3 and adopted by Armen and Essa Best, who renamed him James and raised him in rural Indiana. Best served in the Army during World War II before launching his acting career. In the 1950s and 1960s, he accumulated scores of credits, playing a range of colorful supporting characters in such TV shows as \"The Twilight Zone,\" \"Bonanza,\" \"The Andy Griffith Show\" and \"Gunsmoke.\" He later appeared in a handful of Burt Reynolds\\' movies, including \"Hooper\" and \"The End.\" But Best will always be best known for his \"Hazzard\" role, which lives on in reruns. \"Jimmie was my teacher, mentor, close friend and collaborator for 26 years,\" Latshaw said. \"I directed two of his feature films, including the recent \\'Return of the Killer Shrews,\\' a sequel he co-wrote and was quite proud of as he had made the first one more than 50 years earlier.\" People we\\'ve lost in 2015 . CNN\\'s Stella Chan contributed to this story.', 'highlights': 'James Best, who played the sheriff on \"The Dukes of Hazzard,\" died Monday at 88 .\\n\"Hazzard\" ran from 1979 to 1985 and was among the most popular shows on TV .', 'id': '00200e794fa41d3f7ce92cbf43e9fd4cd652bb09'}\n"
          ]
        }
      ],
      "source": [
        "print(sample_cnn[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8",
      "metadata": {
        "id": "1051e780-8871-4fd4-9e18-68ad8bc837f8"
      },
      "source": [
        "Now We have the Dataset with the prompt and the Reference Summary, it is time to create a Dataset in LangSmith with this information.\n",
        "### Create the Dataset in Langsmith\n",
        "\n",
        "The dataset in LangSmith is composed of an input, which is the prompt passed to the model for evaluation, and an output, which should contain what we expect the model to return."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
      "metadata": {
        "id": "ed9c00f6-f9ad-423f-8a8f-86fdfd30bfe0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
      "metadata": {
        "id": "221d8e92-c2f1-499c-9e68-3abb752722c4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "input_key=['article']\n",
        "output_key=['highlights']\n",
        "\n",
        "NAME_DATASET=f\"Summarize_dataset_{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "dcf23c41-e15d-4f63-bd27-233d6599e305",
        "outputId": "93c87959-f846-422c-bd04-3f897b2edfba",
        "scrolled": true,
        "tags": [],
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-4f9a366762e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert the Hugging Face Dataset to a pandas DataFrame explicitly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msample_cnn_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m dataset = client.upload_dataframe(\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_cnn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Use the converted DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[1;32m    852\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                         \u001b[0;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_of_dict_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_of_series_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_of_dict_to_arrays\u001b[0;34m(data, columns)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0msort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mpre_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_unique_multiple_list_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0;31m# assure that they are of the base dict class and not of derived\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7647\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7648\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7649\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"index must be specified when data is not list-like\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_dtype_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert numpy.ndarray to numpy.ndarray"
          ]
        }
      ],
      "source": [
        "# #This creates the dataset in LangSmith with the content in sample_cnn - If you run this more than once you will get POST errors\n",
        "client = Client(api_key=userdata.get('LANGCHAIN_API_KEY'))\n",
        "# Convert the Hugging Face Dataset to a pandas DataFrame explicitly\n",
        "import pandas as pd\n",
        "sample_cnn_df = pd.DataFrame(sample_cnn)\n",
        "dataset = client.upload_dataframe(\n",
        "    df=sample_cnn_df, # Use the converted DataFrame\n",
        "    input_keys=input_key,\n",
        "    output_keys=output_key,\n",
        "    name=NAME_DATASET,\n",
        "    description=\"Test Embedding distance between model summarizations\",\n",
        "    data_type=\"kv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada2bd55-b6bc-467c-b481-48d46ad50441",
      "metadata": {
        "id": "ada2bd55-b6bc-467c-b481-48d46ad50441"
      },
      "source": [
        "In this image, we can see an example from the dataset once it's been registered in LangSmith.\n",
        "\n",
        "In the Input column, there is the prompt to be sent, while in the Output column, the expected output is stored.\n",
        "\n",
        "When performing the comparison, the model will be given the prompt, and the Cosine distance between its response and the one stored in the sample dataset will be calculated.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Dataset.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8278f53f-1a94-407c-846d-05c926737704",
      "metadata": {
        "id": "8278f53f-1a94-407c-846d-05c926737704"
      },
      "source": [
        "### Recovering Models From Hugging Face\n",
        "Let's retrieve both models from HuggingFace. A base T5 model and a model that has been fine-tuned using the training portion of this same dataset to generate summaries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "fyT-ZBmvtmms"
      },
      "id": "fyT-ZBmvtmms",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
      "metadata": {
        "id": "0f1afd20-0bbe-473b-9ad9-ebceb3519421",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
      "metadata": {
        "id": "12339bcc-ce70-4fae-9dcb-f2f273429ed8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "summarizer_base = HuggingFaceHub(\n",
        "    repo_id=\"t5-base\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
      "metadata": {
        "id": "f317d1cc-95f0-4f71-9c7f-205e42afc5df",
        "tags": []
      },
      "outputs": [],
      "source": [
        "summarizer_finetuned = HuggingFaceHub(\n",
        "    repo_id=\"flax-community/t5-base-cnn-dm\",\n",
        "    model_kwargs={\"temperature\":0, \"max_length\":180},\n",
        "    huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6",
      "metadata": {
        "id": "dc859325-3e92-4f2b-85cc-247dd84d9cf6"
      },
      "source": [
        "## Defining Evaluator\n",
        "The first step is to define an evaluator, where we specify the variables we want to evaluate. In our case, I have chosen to measure only the \"embedding_distance.\"\n",
        "\n",
        "I've left the \"string_distance\" as a comment in case you want to conduct a test with two evaluations instead of one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
      "metadata": {
        "id": "d506d770-2c30-41a6-acde-283ad1b27ea9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.smith import run_on_dataset, RunEvalConfig\n",
        "# !pip install -q rapidfuzz==3.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
      "metadata": {
        "id": "15e8accd-d7e1-44f8-b5d0-0215ceedb88d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#We are using just one of the multiple evaluator avaiable on LangSmith.\n",
        "\n",
        "evaluation_config = RunEvalConfig(\n",
        "    evaluators=[\n",
        "        \"embedding_distance\",\n",
        "        #\"string_distance\"\n",
        "    ],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee666c30-d958-45b1-802c-7034dd13b42b",
      "metadata": {
        "id": "ee666c30-d958-45b1-802c-7034dd13b42b"
      },
      "source": [
        "### Running Evaluator\n",
        "With the same configuration, we can launch two evaluations on the same dataset. One for each of the chosen models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c75c07-8351-465f-af15-a1abe17968f9",
      "metadata": {
        "id": "67c75c07-8351-465f-af15-a1abe17968f9",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "project_name = f\"T5-BASE {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "base_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_base,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
      "metadata": {
        "id": "76ede4d6-ed51-4745-b91a-d9ec6c40d436",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Ignore the error shown below\n",
        "project_name = f\"T5-FineTuned {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=summarizer_finetuned,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159",
      "metadata": {
        "id": "953211fe-b8a4-4a2c-91e3-3c6242a2f159"
      },
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_Tests.jpg?raw=true\">\n",
        "\n",
        "In the image below you can see the comparision between two tests.\n",
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareTestst.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Xn6jeX7u_4MR",
      "metadata": {
        "id": "Xn6jeX7u_4MR"
      },
      "source": [
        "Well, since it has been so straightforward, why don't we try to make the comparison with an OpenAI model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a97ac1-623e-4d28-a78b-c807af89c918",
      "metadata": {
        "id": "84a97ac1-623e-4d28-a78b-c807af89c918"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "open_aillm=OpenAI(temperature=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suc0G-9W94Qj",
      "metadata": {
        "id": "suc0G-9W94Qj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "project_name = f\"OpenAI {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "finetuned_t5_results = run_on_dataset(\n",
        "    client=client,\n",
        "    project_name=project_name,\n",
        "    dataset_name=NAME_DATASET,\n",
        "    llm_or_chain_factory=open_aillm,\n",
        "    evaluation=evaluation_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B15V_-3pBvOK",
      "metadata": {
        "id": "B15V_-3pBvOK"
      },
      "source": [
        "<img src=\"https://github.com/peremartra/Large-Language-Model-Notebooks-Course/blob/main/img/Martra_Figure_4_2SDL_CompareOpenAI_HF.jpg?raw=true\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fUeZWvLMCOBw",
      "metadata": {
        "id": "fUeZWvLMCOBw"
      },
      "source": [
        "The experiment with the OpenAI model has yielded the best results. But, be aware! As we can see, there is a cost involved since we are using an API, and it needs to be paid for.\n",
        "\n",
        "Another crucial piece of information is that we can view performance data for the models. This data could also be useful for minimally evaluating our inference server."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}